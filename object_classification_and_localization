{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Alireza-Akhavan/object-detection-notebooks.git"
      ],
      "metadata": {
        "id": "RWW0hXBzAEen",
        "outputId": "ec0f6787-4cdc-45a5-a762-48bf443695f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RWW0hXBzAEen",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'object-detection-notebooks'...\n",
            "remote: Enumerating objects: 2083, done.\u001b[K\n",
            "remote: Counting objects: 100% (2083/2083), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2078/2078), done.\u001b[K\n",
            "remote: Total 2083 (delta 9), reused 2069 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (2083/2083), 26.78 MiB | 40.93 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Flatten, Dense, Input, Dropout\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pickle"
      ],
      "metadata": {
        "id": "JOA0VUfwA6Zi"
      },
      "id": "JOA0VUfwA6Zi",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = '/content/object-detection-notebooks/dataset2'\n",
        "IMAGE_PATH = os.path.sep.join([BASE_PATH, \"images\"])\n",
        "ANNOTS_PATH = os.path.sep.join([BASE_PATH, \"annotations\"])\n",
        "\n",
        "print(IMAGE_PATH)\n",
        "print(ANNOTS_PATH)"
      ],
      "metadata": {
        "id": "qryHSkryBu_7",
        "outputId": "84592fa0-f559-4b8a-ea7f-20d3d8b6a081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qryHSkryBu_7",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/object-detection-notebooks/dataset2/images\n",
            "/content/object-detection-notebooks/dataset2/annotations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []\n",
        "bbox = []\n",
        "image_paths = []"
      ],
      "metadata": {
        "id": "wQHGYk5golUT"
      },
      "id": "wQHGYk5golUT",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csvPaths = []\n",
        "for root, dirs, files in os.walk(ANNOTS_PATH):\n",
        "  for file in files:\n",
        "    file_extension = file.split('.')[-1]\n",
        "\n",
        "    if file_extension == 'csv':\n",
        "      csvPath = os.path.join(root, file)\n",
        "      csvPaths.append(csvPath)\n",
        "\n",
        "csvPaths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10P0cQlnowlh",
        "outputId": "727e7231-b715-495f-e7cb-944a49f7858d"
      },
      "id": "10P0cQlnowlh",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/object-detection-notebooks/dataset2/annotations/face.csv',\n",
              " '/content/object-detection-notebooks/dataset2/annotations/airplane.csv',\n",
              " '/content/object-detection-notebooks/dataset2/annotations/motorcycle.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for csvPath in csvPaths:\n",
        "  rows = open(csvPath).read().strip().split(\"\\n\")\n",
        "\n",
        "  for row in rows:\n",
        "    row = row.split(\",\")\n",
        "    (filename, startX, startY, endX, endY, label) = row\n",
        "\n",
        "    image_path = os.path.join(IMAGE_PATH, label, filename)\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    (h, w) = image.shape[:2]\n",
        "\n",
        "    startX = float(startX) / w\n",
        "    startY = float(startY) / h\n",
        "    endX = float(endX) / w\n",
        "    endY = float(endY) / h\n",
        "\n",
        "    image = load_img(image_path, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "\n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        "    bbox.append((startX, startY, endX, endY))\n",
        "    image_paths.append(image_path)"
      ],
      "metadata": {
        "id": "Q17FvoqEpLhF"
      },
      "id": "Q17FvoqEpLhF",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data, dtype=\"float32\") / 255.0\n",
        "labels = np.array(labels)\n",
        "bbox = np.array(bbox, dtype=\"float32\")\n",
        "image_paths = np.array(image_paths)"
      ],
      "metadata": {
        "id": "mUxnu7_lJRD5"
      },
      "id": "mUxnu7_lJRD5",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform( labels)"
      ],
      "metadata": {
        "id": "jZjzV45zKVQl"
      },
      "id": "jZjzV45zKVQl",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lb.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNmDgyBRKn_G",
        "outputId": "6554d0ca-bd03-4d48-ef1d-075c5b09033b"
      },
      "id": "WNmDgyBRKn_G",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['airplane', 'face', 'motorcycle'], dtype='<U10')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split = train_test_split(data, labels, bbox, image_paths, test_size=0.2, random_state=42)\n",
        "\n",
        "(train_images, test_images) = split[:2]\n",
        "(train_labels, test_labels) = split[2:4]\n",
        "(trainBBox, testBBox) = split[4:6]\n",
        "(trainPaths, testPaths) = split[6:]"
      ],
      "metadata": {
        "id": "6g2pIbtkLT1N"
      },
      "id": "6g2pIbtkLT1N",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkIZrPobMJrr",
        "outputId": "a8be560a-c7ab-4790-98e6-5091ceabb84c"
      },
      "id": "dkIZrPobMJrr",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1626, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDHguGDBMMkj",
        "outputId": "bf4d8d13-7f08-4cf1-a69c-338f7e94b3c6"
      },
      "id": "CDHguGDBMMkj",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg.trainable = False"
      ],
      "metadata": {
        "id": "PE-Zf1cbMcE9"
      },
      "id": "PE-Zf1cbMcE9",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = vgg.output\n",
        "flatten = Flatten()(flatten)\n",
        "\n",
        "bboxHead = Dense(128, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(4, activation=\"sigmoid\", name = \"bounding_box\")(bboxHead)\n",
        "\n",
        "softmaxHead = Dense(512, activation=\"relu\")(flatten)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(len(lb.classes_), activation=\"softmax\", name = \"class_label\")(softmaxHead)\n",
        "\n",
        "model = Model(inputs=vgg.input, outputs=(bboxHead, softmaxHead))"
      ],
      "metadata": {
        "id": "V5bzFt7cMhNT"
      },
      "id": "V5bzFt7cMhNT",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = {\n",
        "    \"class_label\": \"categorical_crossentropy\",\n",
        "    \"bounding_box\": \"mean_squared_error\",\n",
        "}\n",
        "\n",
        "lossWeights = {\n",
        "    \"class_label\": 1.0,\n",
        "    \"bounding_box\": 1.0,\n",
        "}\n",
        "\n",
        "metrics = {\n",
        "    \"class_label\": \"accuracy\"\n",
        "}"
      ],
      "metadata": {
        "id": "m2H6PNsMOU5I"
      },
      "id": "m2H6PNsMOU5I",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(learning_rate = 1e-4)\n",
        "model.compile(loss=losses, optimizer=opt, metrics=metrics, loss_weights=lossWeights)"
      ],
      "metadata": {
        "id": "d6AaQfZKREhB"
      },
      "id": "d6AaQfZKREhB",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainTargets = {\n",
        "    \"class_label\": train_labels,\n",
        "    \"bounding_box\": trainBBox\n",
        "}\n",
        "\n",
        "testTargets={\n",
        "    \"class_label\": test_labels,\n",
        "    \"bounding_box\": testBBox\n",
        "}"
      ],
      "metadata": {
        "id": "pIaVGWh3Rjn0"
      },
      "id": "pIaVGWh3Rjn0",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H = model.fit(\n",
        "    train_images, trainTargets,\n",
        "    validation_data = (test_images, testTargets),\n",
        "    batch_size = 32,\n",
        "    epochs = 20,\n",
        "    verbose = 1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFjQETXCR-AK",
        "outputId": "964f573e-489e-408b-fc31-50a8e75b7048"
      },
      "id": "vFjQETXCR-AK",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 309ms/step - bounding_box_loss: 5.4025e-04 - class_label_accuracy: 1.0000 - class_label_loss: 2.1604e-04 - loss: 7.5634e-04 - val_bounding_box_loss: 0.0012 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 1.6375e-05 - val_loss: 0.0012\n",
            "Epoch 2/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 214ms/step - bounding_box_loss: 1.1771e-04 - class_label_accuracy: 0.9997 - class_label_loss: 0.0019 - loss: 0.0020 - val_bounding_box_loss: 0.0012 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 3.3264e-05 - val_loss: 0.0012\n",
            "Epoch 3/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - bounding_box_loss: 8.5830e-05 - class_label_accuracy: 0.9981 - class_label_loss: 0.0048 - loss: 0.0049 - val_bounding_box_loss: 0.0012 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 2.5663e-04 - val_loss: 0.0014\n",
            "Epoch 4/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 228ms/step - bounding_box_loss: 7.5189e-05 - class_label_accuracy: 0.9999 - class_label_loss: 0.0011 - loss: 0.0012 - val_bounding_box_loss: 0.0011 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 3.7976e-05 - val_loss: 0.0012\n",
            "Epoch 5/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - bounding_box_loss: 7.6787e-05 - class_label_accuracy: 0.9951 - class_label_loss: 0.0062 - loss: 0.0063 - val_bounding_box_loss: 0.0012 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 1.0476e-04 - val_loss: 0.0013\n",
            "Epoch 6/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 221ms/step - bounding_box_loss: 8.1964e-05 - class_label_accuracy: 0.9980 - class_label_loss: 0.0060 - loss: 0.0061 - val_bounding_box_loss: 0.0011 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 5.4360e-05 - val_loss: 0.0012\n",
            "Epoch 7/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 219ms/step - bounding_box_loss: 7.8695e-05 - class_label_accuracy: 1.0000 - class_label_loss: 8.0596e-05 - loss: 1.5930e-04 - val_bounding_box_loss: 0.0011 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 5.4377e-06 - val_loss: 0.0011\n",
            "Epoch 8/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 217ms/step - bounding_box_loss: 9.0921e-05 - class_label_accuracy: 0.9997 - class_label_loss: 0.0018 - loss: 0.0019 - val_bounding_box_loss: 0.0012 - val_class_label_accuracy: 0.9975 - val_class_label_loss: 0.0080 - val_loss: 0.0094\n",
            "Epoch 9/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 217ms/step - bounding_box_loss: 6.9883e-05 - class_label_accuracy: 1.0000 - class_label_loss: 7.9723e-04 - loss: 8.6715e-04 - val_bounding_box_loss: 0.0011 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 2.0861e-07 - val_loss: 0.0011\n",
            "Epoch 10/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 218ms/step - bounding_box_loss: 8.7084e-05 - class_label_accuracy: 0.9997 - class_label_loss: 9.6433e-04 - loss: 0.0011 - val_bounding_box_loss: 0.0011 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 3.7202e-05 - val_loss: 0.0012\n",
            "Epoch 11/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 218ms/step - bounding_box_loss: 7.7188e-05 - class_label_accuracy: 0.9969 - class_label_loss: 0.0077 - loss: 0.0078 - val_bounding_box_loss: 0.0011 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 6.2045e-06 - val_loss: 0.0011\n",
            "Epoch 12/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 217ms/step - bounding_box_loss: 6.0209e-05 - class_label_accuracy: 1.0000 - class_label_loss: 3.1202e-04 - loss: 3.7291e-04 - val_bounding_box_loss: 0.0011 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 1.4729e-07 - val_loss: 0.0011\n",
            "Epoch 13/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 217ms/step - bounding_box_loss: 5.4141e-05 - class_label_accuracy: 0.9990 - class_label_loss: 0.0011 - loss: 0.0011 - val_bounding_box_loss: 0.0012 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 1.1741e-04 - val_loss: 0.0013\n",
            "Epoch 14/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 218ms/step - bounding_box_loss: 5.0277e-05 - class_label_accuracy: 1.0000 - class_label_loss: 4.5739e-05 - loss: 9.6041e-05 - val_bounding_box_loss: 0.0011 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 2.9964e-06 - val_loss: 0.0011\n",
            "Epoch 15/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 232ms/step - bounding_box_loss: 5.0358e-05 - class_label_accuracy: 1.0000 - class_label_loss: 2.9873e-05 - loss: 8.0244e-05 - val_bounding_box_loss: 0.0011 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 4.0345e-07 - val_loss: 0.0011\n",
            "Epoch 16/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 221ms/step - bounding_box_loss: 6.0036e-05 - class_label_accuracy: 0.9983 - class_label_loss: 0.0047 - loss: 0.0048 - val_bounding_box_loss: 0.0011 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 2.1267e-06 - val_loss: 0.0012\n",
            "Epoch 17/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 221ms/step - bounding_box_loss: 6.8600e-05 - class_label_accuracy: 0.9986 - class_label_loss: 0.0042 - loss: 0.0043 - val_bounding_box_loss: 0.0011 - val_class_label_accuracy: 0.9975 - val_class_label_loss: 0.0112 - val_loss: 0.0126\n",
            "Epoch 18/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 220ms/step - bounding_box_loss: 7.4561e-05 - class_label_accuracy: 0.9995 - class_label_loss: 9.3468e-04 - loss: 0.0010 - val_bounding_box_loss: 0.0011 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 6.7055e-08 - val_loss: 0.0011\n",
            "Epoch 19/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 218ms/step - bounding_box_loss: 5.7482e-05 - class_label_accuracy: 1.0000 - class_label_loss: 5.6376e-05 - loss: 1.1386e-04 - val_bounding_box_loss: 0.0012 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 1.8626e-08 - val_loss: 0.0012\n",
            "Epoch 20/20\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 218ms/step - bounding_box_loss: 7.6396e-05 - class_label_accuracy: 1.0000 - class_label_loss: 2.3543e-05 - loss: 9.9948e-05 - val_bounding_box_loss: 0.0012 - val_class_label_accuracy: 1.0000 - val_class_label_loss: 1.0030e-08 - val_loss: 0.0012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yNoah55NScWq"
      },
      "id": "yNoah55NScWq",
      "execution_count": 20,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}