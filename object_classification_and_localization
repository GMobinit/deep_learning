{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Alireza-Akhavan/object-detection-notebooks.git"
      ],
      "metadata": {
        "id": "RWW0hXBzAEen",
        "outputId": "7ed65eb0-b2ba-41ee-f285-ab337116cf22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RWW0hXBzAEen",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'object-detection-notebooks'...\n",
            "remote: Enumerating objects: 2083, done.\u001b[K\n",
            "remote: Counting objects: 100% (2083/2083), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2078/2078), done.\u001b[K\n",
            "remote: Total 2083 (delta 9), reused 2069 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (2083/2083), 26.78 MiB | 34.54 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Flatten, Dense, Input, Dropout\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pickle"
      ],
      "metadata": {
        "id": "JOA0VUfwA6Zi"
      },
      "id": "JOA0VUfwA6Zi",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = '/content/object-detection-notebooks/dataset2'\n",
        "IMAGE_PATH = os.path.sep.join([BASE_PATH, \"images\"])\n",
        "ANNOTS_PATH = os.path.sep.join([BASE_PATH, \"annotations\"])\n",
        "\n",
        "print(IMAGE_PATH)\n",
        "print(ANNOTS_PATH)"
      ],
      "metadata": {
        "id": "qryHSkryBu_7",
        "outputId": "a579bb87-d0f4-44a4-e117-468c02e30c9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qryHSkryBu_7",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/object-detection-notebooks/dataset2/images\n",
            "/content/object-detection-notebooks/dataset2/annotations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []\n",
        "bbox = []\n",
        "image_paths = []"
      ],
      "metadata": {
        "id": "wQHGYk5golUT"
      },
      "id": "wQHGYk5golUT",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csvPaths = []\n",
        "for root, dirs, files in os.walk(ANNOTS_PATH):\n",
        "  for file in files:\n",
        "    file_extension = file.split('.')[-1]\n",
        "\n",
        "    if file_extension == 'csv':\n",
        "      csvPath = os.path.join(root, file)\n",
        "      csvPaths.append(csvPath)\n",
        "\n",
        "csvPaths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10P0cQlnowlh",
        "outputId": "7b9910e7-1c61-4934-ae12-815b55f97d3d"
      },
      "id": "10P0cQlnowlh",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/object-detection-notebooks/dataset2/annotations/face.csv',\n",
              " '/content/object-detection-notebooks/dataset2/annotations/airplane.csv',\n",
              " '/content/object-detection-notebooks/dataset2/annotations/motorcycle.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for csvPath in csvPaths:\n",
        "  rows = open(csvPath).read().strip().split(\"\\n\")\n",
        "\n",
        "  for row in rows:\n",
        "    row = row.split(\",\")\n",
        "    (filename, startX, startY, endX, endY, label) = row\n",
        "\n",
        "    image_path = os.path.join(IMAGE_PATH, label, filename)\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    (h, w) = image.shape[:2]\n",
        "\n",
        "    startX = float(startX) / w\n",
        "    startY = float(startY) / h\n",
        "    endX = float(endX) / w\n",
        "    endY = float(endY) / h\n",
        "\n",
        "    image = load_img(image_path, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "\n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        "    bbox.append((startX, startY, endX, endY))\n",
        "    image_paths.append(image_path)"
      ],
      "metadata": {
        "id": "Q17FvoqEpLhF"
      },
      "id": "Q17FvoqEpLhF",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data, dtype=\"float32\") / 255.0\n",
        "labels = np.array(labels)\n",
        "bbox = np.array(bbox, dtype=\"float32\")\n",
        "image_paths = np.array(image_paths)"
      ],
      "metadata": {
        "id": "mUxnu7_lJRD5"
      },
      "id": "mUxnu7_lJRD5",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform( labels)"
      ],
      "metadata": {
        "id": "jZjzV45zKVQl"
      },
      "id": "jZjzV45zKVQl",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lb.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNmDgyBRKn_G",
        "outputId": "63634a13-9c35-4b58-c4ab-a95c54293890"
      },
      "id": "WNmDgyBRKn_G",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['airplane', 'face', 'motorcycle'], dtype='<U10')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split = train_test_split(data, labels, bbox, image_paths, test_size=0.2, random_state=42)\n",
        "\n",
        "(train_images, test_images) = split[:2]\n",
        "(train_labels, test_labels) = split[2:4]\n",
        "(trainBBox, testBBox) = split[4:6]\n",
        "(trainPaths, testPaths) = split[6:]"
      ],
      "metadata": {
        "id": "6g2pIbtkLT1N"
      },
      "id": "6g2pIbtkLT1N",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkIZrPobMJrr",
        "outputId": "4b7b57fd-189a-4028-e22b-466a14430a5a"
      },
      "id": "dkIZrPobMJrr",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1626, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDHguGDBMMkj",
        "outputId": "8151cd35-b667-45f0-bd32-63fffbfb1bc0"
      },
      "id": "CDHguGDBMMkj",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg.trainable = False"
      ],
      "metadata": {
        "id": "PE-Zf1cbMcE9"
      },
      "id": "PE-Zf1cbMcE9",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = vgg.output\n",
        "flatten = Flatten()(flatten)\n",
        "\n",
        "bboxHead = Dense(128, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(4, activation=\"sigmoid\", name = \"bounding_box\")(bboxHead)\n",
        "\n",
        "softmaxHead = Dense(512, activation=\"relu\")(flatten)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(len(lb.classes_), activation=\"softmax\", name = \"class_label\")(softmaxHead)\n",
        "\n",
        "model = Model(inputs=vgg.input, outputs=(bboxHead, softmaxHead))"
      ],
      "metadata": {
        "id": "V5bzFt7cMhNT"
      },
      "id": "V5bzFt7cMhNT",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = {\n",
        "    \"class_label\": \"categorical_crossentropy\",\n",
        "    \"bounding_box\": \"mean_squared_error\",\n",
        "}\n",
        "\n",
        "lossWeights = {\n",
        "    \"class_label\": 1.0,\n",
        "    \"bounding_box\": 1.0,\n",
        "}\n",
        "\n",
        "metrics = {\n",
        "    \"class_label\": \"accuracy\"\n",
        "}"
      ],
      "metadata": {
        "id": "m2H6PNsMOU5I"
      },
      "id": "m2H6PNsMOU5I",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(learning_rate = 1e-4)\n",
        "model.compile(loss=losses, optimizer=opt, metrics=metrics, loss_weights=lossWeights)"
      ],
      "metadata": {
        "id": "d6AaQfZKREhB"
      },
      "id": "d6AaQfZKREhB",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainTargets = {\n",
        "    \"class_label\": train_labels,\n",
        "    \"bounding_box\": trainBBox\n",
        "}\n",
        "\n",
        "testTargets={\n",
        "    \"class_label\": test_labels,\n",
        "    \"bounding_box\": testBBox\n",
        "}"
      ],
      "metadata": {
        "id": "pIaVGWh3Rjn0"
      },
      "id": "pIaVGWh3Rjn0",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H = model.fit(\n",
        "    train_images, trainTargets,\n",
        "    validation_data = (test_images, testTargets),\n",
        "    batch_size = 32,\n",
        "    epochs = 20,\n",
        "    verbose = 1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFjQETXCR-AK",
        "outputId": "5cff3763-3141-4ed8-c495-d13bc322fd7a"
      },
      "id": "vFjQETXCR-AK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m10/51\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:20\u001b[0m 20s/step - bounding_box_loss: 0.0789 - class_label_accuracy: 0.5708 - class_label_loss: 0.8651 - loss: 0.9440"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('object_and_box_reco.keras')\n",
        "with open('lb3.pickle', \"wb\") as f:\n",
        "  f.write(pickle.dumps(lb))"
      ],
      "metadata": {
        "id": "yNoah55NScWq"
      },
      "id": "yNoah55NScWq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lossNames = [\"loss\", \"class_label_loss\", \"bounding_box_loss\"]\n",
        "N = np.arange(0, H.params['epochs'])\n",
        "plt.style.use(\"ggplot\")\n",
        "(fig, ax) = plt.subplots(3, 1, figsize=(13, 13))\n",
        "\n",
        "# loop over the loss names\n",
        "for (i, l) in enumerate(lossNames):\n",
        "    # plot the loss for both the training and validation data\n",
        "    title = \"Loss for {}\".format(l) if l != \"loss\" else \"Total loss\"\n",
        "    ax[i].set_title(title)\n",
        "    ax[i].set_xlabel(\"Epoch #\")\n",
        "    ax[i].set_ylabel(\"Loss\")\n",
        "    ax[i].plot(N, H.history[l], label=l)\n",
        "    ax[i].plot(N, H.history[\"val_\" + l], label=\"val_\" + l)\n",
        "    ax[i].legend()\n",
        "\n",
        "# save the losses figure and create a new figure for the accuracies\n",
        "plt.tight_layout()\n",
        "\n",
        "# create a new figure for the accuracies\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N, H.history[\"class_label_accuracy\"], label=\"class_label_train_acc\")\n",
        "plt.plot(N, H.history[\"val_class_label_accuracy\"], label=\"val_class_label_acc\")\n",
        "plt.title(\"Class Label Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc=\"lower left\")"
      ],
      "metadata": {
        "id": "c7u2dJ31PYOS"
      },
      "id": "c7u2dJ31PYOS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using trained Model"
      ],
      "metadata": {
        "id": "Nji9WazrRzhe"
      },
      "id": "Nji9WazrRzhe"
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('object_and_box_reco.keras')\n",
        "lb = pickle.loads(open('lb3.pickle', \"rb\").read())\n",
        "print(lb.classes_)"
      ],
      "metadata": {
        "id": "-Y9BY1NERzLF"
      },
      "id": "-Y9BY1NERzLF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_inference(img_path):\n",
        "  image = load_img(img_path, target_size=(224, 224))\n",
        "  image = img_to_array(image) / 255.0\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "  print(image.shape)\n",
        "  return model.predict(image)"
      ],
      "metadata": {
        "id": "f2K2CCzdSDS0"
      },
      "id": "f2K2CCzdSDS0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_label(predicted_array: np.ndarray):\n",
        "  return  lb.classes_[np.argmax(predicted_array)]"
      ],
      "metadata": {
        "id": "N1eFw-JbWb9y"
      },
      "id": "N1eFw-JbWb9y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_box(img, predicted_box_array, label):\n",
        "  image = np.copy(img)\n",
        "  (h,w) = image.shape[:2]\n",
        "\n",
        "  (startX, startY, endX, endY) = predicted_box_array\n",
        "\n",
        "  startX = int(startX * w)\n",
        "  startY = int(startY * h)\n",
        "  endX = int(endX * w)\n",
        "  endY = int(endY * h)\n",
        "  y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "\n",
        "  cv2.putText(image, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0,255,0), 2)\n",
        "  cv2.rectangle(image, (startX, startY), (endX, endY), (0,255,0),2)\n",
        "\n",
        "  return image\n"
      ],
      "metadata": {
        "id": "nWLAMug9f634"
      },
      "id": "nWLAMug9f634",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_box, prediction_label = image_inference(\"/content/WIN_20251122_20_43_01_Pro.jpg\")"
      ],
      "metadata": {
        "id": "1ZxmONNWjwNC"
      },
      "id": "1ZxmONNWjwNC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(find_label(prediction_label))\n",
        "print(prediction_box)"
      ],
      "metadata": {
        "id": "ID0AIWoajtpm"
      },
      "id": "ID0AIWoajtpm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(\"/content/WIN_20251122_19_44_16_Pro.jpg\")\n",
        "label = find_label(prediction_label)\n",
        "img = draw_box(img, prediction_box[0], label)\n",
        "image = cv2.imshow(img)"
      ],
      "metadata": {
        "id": "F_N-6taziXFc"
      },
      "id": "F_N-6taziXFc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q5XZcFEVi6eg"
      },
      "id": "Q5XZcFEVi6eg",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}